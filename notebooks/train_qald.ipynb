{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Q4MCWngFbCe_",
    "outputId": "7c7b6158-6d77-4da7-980a-38f5a4c18bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "\n",
    "# load BERT modules\n",
    "from official import nlp\n",
    "import official.nlp.bert as bert\n",
    "import official.nlp.bert.tokenization as tokenization\n",
    "import official.nlp.bert.configs as configs\n",
    "import official.nlp.bert.bert_models as bert_models\n",
    "import official.nlp.optimization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle as shuffle_sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import mlflow\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "print(f'Tensorflow version {tf.__version__}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "# disable warning messages\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "EXPERIMENT_NAME = 'Answer_Validation_Labels'\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:41250\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ['/home/aperevalov/answer_validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_load(name):\n",
    "    with open(f'{name}.json', 'r', encoding = 'utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def json_save(name, item):\n",
    "    with open(f'{name}.json', 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(item, f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eSnBrrAJIhB6",
    "outputId": "a5ad2255-65c2-4618-fee6-0bb73e6e07cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# make path from elements so it works both on windows and linux \n",
    "file_bert = ['vocab.txt']\n",
    "\n",
    "# set up tokenizer to generate Tensorflow dataset\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=os.path.join(*file_bert))\n",
    "\n",
    "print(f'Vocab size: {len(tokenizer.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "kKd9iEyLe9jb",
    "outputId": "049c03ff-518a-4eb6-ee54-2a7b5587e839"
   },
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'attention_probs_dropout_prob': 0.1,\n",
    "    'hidden_act': 'gelu',\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'hidden_size': 768,\n",
    "    'initializer_range': 0.02,\n",
    "    'intermediate_size': 3072,\n",
    "    'max_position_embeddings': 512,\n",
    "    'num_attention_heads': 12,\n",
    "    'num_hidden_layers': 12,\n",
    "    'type_vocab_size': 2,\n",
    "    'vocab_size': 30522}\n",
    "\n",
    "bert_config = configs.BertConfig.from_dict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sentence to tokens\n",
    "def encode_sentence(s):\n",
    "    tokens = list(tokenizer.tokenize(s)) + ['[SEP]']\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def encode_pair(q, a, max_size):\n",
    "    q_tok = ['[CLS]'] + tokenizer.tokenize(q) + ['[SEP]']\n",
    "    a_tok = tokenizer.tokenize(a) + ['[SEP]']\n",
    "    ids = tokenizer.convert_tokens_to_ids(q_tok + a_tok)\n",
    "    \n",
    "    if len(ids) > max_size:\n",
    "        raise IndexError('Too many tokens')\n",
    "    else:\n",
    "        inputs = {\n",
    "            'input_word_ids': ids + [0]*(max_size - len(ids)),\n",
    "            'input_mask': [1]*len(ids) + [0]*(max_size - len(ids)),\n",
    "            'input_type_ids': [0]*len(q_tok) + [1]*len(a_tok) + [0]*(max_size - len(ids))\n",
    "        }\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "assert(encode_sentence('Human is instance of animal') == [2529, 2003, 6013, 1997, 4111, 102])\n",
    "assert(\n",
    "    encode_pair('Who are you?', 'I am your dad.', 15)['input_word_ids'] ==\n",
    "    [101, 2040, 2024, 2017, 1029, 102, 1045, 2572, 2115, 3611, 1012, 102, 0, 0, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(class_0, class_1, tokenizer, size=0, random_state=42):\n",
    "    # random.shuffle(class_0[:size] if size else class_0)\n",
    "    # random.shuffle(class_1[:size] if size else class_1)\n",
    "    \n",
    "    labels = [0]*len(class_0) + [1]*len(class_1)\n",
    "    records = class_0 + class_1\n",
    "\n",
    "    questions = tf.ragged.constant([encode_sentence(s[0]) for s in records])\n",
    "    answers = tf.ragged.constant([encode_sentence(s[1]) for s in records])\n",
    "\n",
    "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*questions.shape[0]\n",
    "    input_word_ids = tf.concat([cls, questions, answers], axis=-1)\n",
    "\n",
    "    input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "    type_cls = tf.zeros_like(cls)\n",
    "    type_question = tf.zeros_like(questions)\n",
    "    type_answer = tf.ones_like(answers)\n",
    "    input_type_ids = tf.concat([type_cls, type_question, type_answer], axis=-1).to_tensor()\n",
    "\n",
    "    inputs = {\n",
    "        'input_word_ids': input_word_ids.to_tensor(),\n",
    "        'input_mask': input_mask,\n",
    "        'input_type_ids': input_type_ids}\n",
    "\n",
    "    return inputs, tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'generates data batches'\n",
    "    def __init__(self, class_0, class_1, embed_len=180, batch_size=32, shuffle=True, random_state=42):\n",
    "        'Initialization'\n",
    "        self.text = class_0 + class_1\n",
    "        self.labels = [0]*len(class_0) + [1]*len(class_1)\n",
    "        self.embed_len = embed_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.count = len(self.text)\n",
    "        self.indexes = list(range(self.count))\n",
    "        self.data = [None]*len(self.text)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.indexes = shuffle_sklearn(self.indexes, random_state=random_state)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.count // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        inputs = {\n",
    "            'input_word_ids': [],\n",
    "            'input_mask': [],\n",
    "            'input_type_ids': []}\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for i in indexes:\n",
    "            if not self.data[i]:\n",
    "                self.data[i] = encode_pair(self.text[i][0], self.text[i][1], self.embed_len)\n",
    "            for key in inputs:\n",
    "                inputs[key] += [self.data[i][key]]\n",
    "            outputs.append(self.labels[i])\n",
    "            \n",
    "        for key in inputs:\n",
    "            inputs[key] = tf.ragged.constant(inputs[key], inner_shape=(self.batch_size, self.embed_len))\n",
    "        outputs = tf.convert_to_tensor(outputs)\n",
    "\n",
    "        return inputs, outputs\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        inputs = {\n",
    "            'input_word_ids': [],\n",
    "            'input_mask': [],\n",
    "            'input_type_ids': []}\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(len(self.text)):\n",
    "            if not self.data[i]:\n",
    "                self.data[i] = encode_pair(self.text[i][0], self.text[i][1], self.embed_len)\n",
    "            for key in inputs:\n",
    "                inputs[key] += [self.data[i][key]]\n",
    "            outputs.append(self.labels[i])\n",
    "            \n",
    "        return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story batch + epoch results and dump to file if name is not empty\n",
    "class HistoryCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, file_name, history={'epoch': [], 'batch': []}):\n",
    "        self.history = history\n",
    "        self.name = file_name\n",
    "        self.epoch = None\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch = epoch + 1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch = epoch + 1\n",
    "        logs['epoch'] = self.epoch\n",
    "        self.history['epoch'].append(logs)\n",
    "        \n",
    "        if self.name:\n",
    "            json_save(self.name, self.history)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if logs and batch:\n",
    "            logs['batch'] = batch\n",
    "            logs['epoch'] = self.epoch\n",
    "            self.history['batch'].append(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def create_train_set_samples(data):\\n    class_0 = []\\n    class_1 = []\\n    \\n    for k, v in data.items():\\n        if v:\\n            for i in v['generated']['right']:\\n                class_1.append([v['vanilla']['question'], i['text'], 1])\\n            for i in v['generated']['wrong']:\\n                class_0.append([v['vanilla']['question'], i['text'], 0])\\n\\n    return class_0, class_1, 'quanswer'\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset for textual representation\n",
    "\"\"\"def create_train_set_samples(data):\n",
    "    class_0 = []\n",
    "    class_1 = []\n",
    "    \n",
    "    for k, v in data.items():\n",
    "        if v:\n",
    "            for i in v['generated']['right']:\n",
    "                class_1.append([v['vanilla']['question'], i['text'], 1])\n",
    "            for i in v['generated']['wrong']:\n",
    "                class_0.append([v['vanilla']['question'], i['text'], 0])\n",
    "\n",
    "    return class_0, class_1, 'quanswer'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_set_samples_qald(data):\n",
    "    class_0 = list()\n",
    "    class_1 = list()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        true_answers = get_list_of_true_answers(qald_dataset[i]['answers']) # from original dataset\n",
    "\n",
    "        for j in range(len(qald[i]['answers'])): # data provided by AlGa\n",
    "            is_answer_correct = if_answer_correct(true_answers, qald[i]['answers'][j])\n",
    "            if is_answer_correct:\n",
    "                if len(data[str(i)][j]) > 0 and len(' '.join(data[str(i)][j]).split()) < 75:\n",
    "                    class_1.append((find_english_in_qald(qald_dataset[i]['question']), ' '.join(data[str(i)][j]))) # my data\n",
    "            else:\n",
    "                if len(data[str(i)][j]) > 0 and len(' '.join(data[str(i)][j]).split()) < 75:\n",
    "                    class_0.append((find_english_in_qald(qald_dataset[i]['question']), ' '.join(data[str(i)][j]))) # my data\n",
    "                # TODO: search for textual answer\n",
    "    \n",
    "    return class_0, class_1, 'labels_qald'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = data_path + ['vanilla_qanswer_results']\n",
    "# data = json_load(os.path.join(os.sep, *data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qald = json_load(\"qald-9-Dbpedia\")\n",
    "data = json_load(\"qald_labels\")\n",
    "\n",
    "qald_test = json_load(\"qald-9-test-multilingual\")\n",
    "qald_train = json_load(\"qald-9-train-multilingual\")\n",
    "\n",
    "qald_dataset = qald_train['questions'] + qald_test['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_english_in_qald(representations):\n",
    "    \"\"\"\n",
    "    representations: qald_dataset[i]['question']\n",
    "    \"\"\"\n",
    "    for r in representations:\n",
    "        if r['language'] == 'en':\n",
    "            return r['string']\n",
    "    \n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_true_answers(qald_answers):\n",
    "    \"\"\"\n",
    "    qald_answers: qald_train['questions'][0]['answers']\n",
    "    \"\"\"\n",
    "    true = list()\n",
    "    if 'bindings' in qald_answers[0]['results']:\n",
    "        for bind in qald_answers[0]['results']['bindings']:\n",
    "            k = list(bind.keys())[0]\n",
    "            true.append(bind[k]['value'])\n",
    "    \n",
    "    return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_answer_correct(true_uri, pred_answer):\n",
    "    \"\"\"\n",
    "    pred_answers: qald[i]['answers'][j]\n",
    "    \"\"\"\n",
    "    uris = list()\n",
    "    if pred_answer['DBpedia']:\n",
    "        for triple in pred_answer['DBpedia']:\n",
    "            for k in list(triple.keys()):\n",
    "                if 'p' not in k and 'dbpedia' in triple[k]['value']:\n",
    "                    uris.append(triple[k]['value'])\n",
    "    # answer_uris.append(uris)\n",
    "    # print(true_uri)\n",
    "    if any(true in uris for true in true_uri):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick consistence check\n",
    "for i in range(len(qald)):\n",
    "    assert len(qald[i]['answers']) == len(data[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_qald\n",
      "11620\n",
      "1481\n"
     ]
    }
   ],
   "source": [
    "class_0, class_1, dataset_name = create_train_set_samples_qald(data)\n",
    "print(dataset_name)\n",
    "print(len(class_0))\n",
    "print(len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Which movies starring Brad Pitt were directed by Guy Ritchie?',\n",
       "  'Snatch (film) Guy Ritchie'),\n",
       " ('Who developed Skype?', 'music genre Web development'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1[50], class_0[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pretrained = ['bert_classifier.h5']\n",
    "\n",
    "def create_model(bert_classifier, epochs=100, batch_size=8, batches_per_epoch=1000, warmup_epochs=5):\n",
    "    num_train_steps = epochs*batch_size*batches_per_epoch\n",
    "    warmup_steps = batches_per_epoch*warmup_epochs\n",
    "\n",
    "    # creates an optimizer with learning rate schedule\n",
    "    optimizer = nlp.optimization.create_optimizer(\n",
    "        2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)\n",
    "\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    bert_classifier.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics)\n",
    "    \n",
    "    bert_classifier.load_weights(os.path.join(*file_pretrained))\n",
    "    \n",
    "    return bert_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(bert_classifier, \n",
    "                class_0, class_1, \n",
    "                valid_0, valid_1, \n",
    "                name,\n",
    "                epochs=5, \n",
    "                batch_size=8, \n",
    "                warmup_epochs=5,\n",
    "                embed=96,\n",
    "                rand_idx=0 # use different random index to shuffle training data\n",
    "               ):\n",
    "    \n",
    "    \n",
    "    rs = list(range(2010, 2020)) # generate random states\n",
    "    \n",
    "    valid_set, valid_labels = bert_encode(valid_0, valid_1, tokenizer) \n",
    "    train = DataGenerator(class_0, class_1, embed_len=embed, batch_size=batch_size, random_state=rs[rand_idx])\n",
    "    n_steps = len(class_0 + class_1) // batch_size # define number of steps per epoch\n",
    "    \n",
    "    history = HistoryCallback(file_name=name, history={'epoch': [], 'batch': []})\n",
    "    \n",
    "    bert_classifier.fit(\n",
    "        train,\n",
    "        steps_per_epoch=n_steps,\n",
    "        validation_data=(valid_set, valid_labels),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            history,\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                             mode='max',\n",
    "                                             patience=1,\n",
    "                                             restore_best_weights=True)\n",
    "        ],\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_0, valid_0 = train_test_split(class_0, test_size=0.1, random_state=4)\n",
    "train_1, valid_1 = train_test_split(class_1, test_size=0.1, random_state=4)\n",
    "\n",
    "train_0, test_0 = train_test_split(train_0, test_size=0.33, random_state=4)\n",
    "train_1, test_1 = train_test_split(train_1, test_size=0.33, random_state=4)\n",
    "\n",
    "test_set, test_labels = bert_encode(test_0, test_1, tokenizer)\n",
    "# print(f\"train size: {len(train_0)}\", f\"val size: {len(valid_0)}\", f\"test size: {len(test_0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "818/818 [==============================] - 231s 283ms/step - loss: 0.4712 - accuracy: 0.7616 - val_loss: 0.2164 - val_accuracy: 0.9222\n",
      "Epoch 2/5\n",
      "496/818 [=================>............] - ETA: 1:28 - loss: 0.1956 - accuracy: 0.9301"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-368198506ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mclass_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mvalid_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'generated.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 batch_size=batch_size, embed=embed, rand_idx=i)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-d281859d5684>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(bert_classifier, class_0, class_1, valid_0, valid_1, name, epochs, batch_size, warmup_epochs, embed, rand_idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                              \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                              \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                              restore_best_weights=True)\n\u001b[0m\u001b[1;32m     33\u001b[0m         ],\n\u001b[1;32m     34\u001b[0m     )    \n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    gc.collect()\n",
    "    \n",
    "    batch_size = 16\n",
    "    embed = 256\n",
    "    \n",
    "    bert_classifier, bert_encoder = bert_models.classifier_model(bert_config, num_labels=2)\n",
    "    bert_classifier = create_model(bert_classifier, batch_size=8)\n",
    "\n",
    "    train_model(bert_classifier, \n",
    "                class_0, class_1,\n",
    "                valid_0, valid_1, 'generated.json',\n",
    "                batch_size=batch_size, embed=embed, rand_idx=i)\n",
    "    \n",
    "    y_pred = bert_classifier.predict(test_set, verbose=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = test_labels.numpy()\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"Rand idx\", i)\n",
    "        mlflow.log_param(\"Batch Size\", batch_size)\n",
    "        mlflow.log_param(\"Embed\", embed)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_score(y_true, y_pred))\n",
    "        mlflow.log_metric(\"Precision\", precision_score(y_true, y_pred))\n",
    "        mlflow.log_metric(\"Recall\", recall_score(y_true, y_pred))\n",
    "        mlflow.log_metric(\"F1 Score\", f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fine-tune-vanilla.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
